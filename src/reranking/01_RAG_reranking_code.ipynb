{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0816eaa4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412,
     "referenced_widgets": [
      "6c8ce6871865490d834d6f6a98b06f23",
      "65b96bee06764f1c9a93eaf5dbfb3265",
      "f3f874abbb6944a2847f8fae85c40ab9",
      "446914e587dd47868eb5579a5fab7fa4",
      "6c28919834284ad7938497e1cb1e5198",
      "7203e68f431a4d829fdc01eaddb769db",
      "9acc1d925a2c445da82e26c3fc67928f",
      "9bdea09062ad4f56a836bc860aa0aa71",
      "3e2ac76fb35542b99af9afb16e6434c5",
      "1cbdb3031ab54ded898004ebb7ba1eb3",
      "e053679b039b4918847feaadbc2e404f",
      "e09dc4b196c342da84fe5b92608431e7",
      "919dcbf6b4914286afade73a9353c0b3",
      "d40cbfe98f3b49c895c5b9cc6036fecd",
      "cd2e9b60b7344834a087cbecddbf787c",
      "4e7c614da76d4d82b503f436240e7050",
      "226df9a72cb7461a953dafe806a34418",
      "b732359a37e843729a93ea5b41715237",
      "1099c464df594b1b8dc589737666cf6d",
      "af655d2218d746d7880684f225fa172b",
      "fc6114e100d949d3bc94730e0e202a89",
      "febf211d5a64430f8b47daaf387d0488",
      "b36ffe4b95324126b53b284f71114282",
      "8d8166340d9a4be7a6f35750586285e3",
      "a52146b7c18c480292b425fa069de564",
      "f77d0befe6164e57b963d78f3901dee5",
      "79fccf717b6e41d0a796b079e328c74e",
      "5e96982716244544af8a06d943feb57a",
      "066a92ba8d8e4914901c1a7aabb979a1",
      "d89da7cd951641968ba59532d2c1e169",
      "34b1bf004eea473297ed7fcd09c6aa96",
      "b8ce909ac22e49faab251350ecd4901b",
      "06b3cff2070d431ea94bfa0cc96ba1e9",
      "b0ac99ef363840fd8d9d9ecd252530ad",
      "7164f0d1ef9b426387156a8ff2b18d1c",
      "9fee592f2e6540a2ab6910d6affba5b2",
      "773c4734f2054f6797eb2c5c9164d713",
      "f246267a63ab4ac68f11ad0dc7c7d86c",
      "5083d46ac0e84c3a8326b36880887d91",
      "d281911a412643d48f29cd1401bbaefe",
      "8447e6d3aefc4d448b1bf4cf9bb9a67f",
      "9d7523026f4d4235a1f66b7fd13acb2a",
      "652b249fcee84392b49846139ae5fb72",
      "7a88a3c6ee684166bdaa003031bde7e6",
      "9609f65af5ad4367afe4ef15c6fbd4c7",
      "bfce1b32e72049b19b79878355c7921e",
      "3e0ba51daf1a42df9cf266c3c7959cf1",
      "9b58b458c8dd4e59908de4fef50703f6",
      "efe14b00ea3841a8896ed7757ee1fb56",
      "e10ab7daaf7649aea4599dc4742c3260",
      "3b244a9b75674cab8641563452c9229d",
      "66e8177d230742c486c40107561f1578",
      "38eca396cbf94fe3808d5dc7e0d6c185",
      "f09467980a3a40a29554a29d579bdaa2",
      "97c5fbd0e9d84db3aef1317fb0b5667d",
      "87ab176ba8ed49129a575c7723c60047",
      "2d513d2df124482e8ff31e80ed0e7c68",
      "7d23d129043345808028080e3ab1d39c",
      "5679eacc81cc4bb1a18983f7947dcf39",
      "bf56ee11bbb845f4863f7fb10414052f",
      "824c1accc719406998b3b016cb12c43a",
      "2417e5467447499d9e0eec0c03617963",
      "ec0be3d103c94774b172edfb309bf510",
      "62a74df32f4b4422a98e2ca643ad3865",
      "ef87eb47a6f74a77a355b0a97697492c",
      "b081a008342a47578ae60b7c10168f41",
      "e7b93a73bbdb49d0a8710544129f8418",
      "f0e5d689152f48869036c45f37ebfb34",
      "585debfe7a7c4e9eb01efd63f8f143c0",
      "793f6e2223d8465a96f391147c170bc9",
      "8cb26479aea342da9adb1751adcc29e0",
      "ea9574b1f3354a85984695a307ed26d0",
      "89b259a7e22e4d6e8b00a0bce2b23ad8",
      "9c80c1a132e44e4aab70451dc517d4d5",
      "c3f2a134713d43a7afa9f08bd34557ac",
      "9d2b2d55974f46d79406c09ed5e5ec65",
      "fcd840dafe4f4df195fd3905ccd3c622",
      "e7de9877f03e41e881f531030d2f5f96",
      "d49ffc5bc9a046ff8ef8d7a379cf71bf",
      "59a7e736ab844a868bdb0d60fbbaafcc",
      "b5f359e626654e25aeb713d99b9f21dc",
      "3b328fc1e5b84be282eb153abdf705f9",
      "7a2cacb61fb14e14bddeae21575f59ca",
      "d176a4a7c32a431cb89d2f6c57b9237b",
      "335b41e7e2bc41aa9761cfe8b72d30df",
      "dac1ef48499740f1bb21f11247086f57",
      "fc57efac2a9d4ce0a8db8bef2c7bce6b",
      "9c05acf671c341c8b7063978cb195fde"
     ]
    },
    "id": "FAOzg-y8s8iI",
    "outputId": "37a24f9f-27b3-44da-8daf-f47874c1043c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8ce6871865490d834d6f6a98b06f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09dc4b196c342da84fe5b92608431e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36ffe4b95324126b53b284f71114282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ac99ef363840fd8d9d9ecd252530ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609f65af5ad4367afe4ef15c6fbd4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ab176ba8ed49129a575c7723c60047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b93a73bbdb49d0a8710544129f8418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7de9877f03e41e881f531030d2f5f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ranking in RAG refers to the process of improving retrieval by scoring the relevance of candidate answers, which enhances the overall quality of generated responses.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load API key securely from environment\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def build_vectorstore(docs: list[str]) -> FAISS:\n",
    "    documents = [Document(page_content=d) for d in docs]\n",
    "    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "    return FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "\n",
    "def rerank(query: str, candidates: list[Document], top_k: int = 3) -> list[Document]:\n",
    "    \"\"\"Use a cross-encoder to re-score retrieved documents.\"\"\"\n",
    "    model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    pairs = [(query, doc.page_content) for doc in candidates]\n",
    "    scores = model.predict(pairs)\n",
    "    ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in ranked[:top_k]]\n",
    "\n",
    "\n",
    "def reranking_rag(query: str, corpus: list[str]) -> str:\n",
    "    store = build_vectorstore(corpus)\n",
    "    # Step 1: Broad retrieval (fetch more than needed)\n",
    "    initial_results = store.similarity_search(query, k=10)\n",
    "    # Step 2: Re-rank with cross-encoder\n",
    "    top_docs = rerank(query, initial_results, top_k=3)\n",
    "\n",
    "    context = \"\\n\".join(doc.page_content for doc in top_docs)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "    response = llm.invoke(\n",
    "        f\"Answer based on context only.\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_corpus = [\n",
    "        \"Python is a high-level programming language.\",\n",
    "        \"RAG combines retrieval with generation for better answers.\",\n",
    "        \"Re-ranking improves retrieval by scoring candidate relevance.\",\n",
    "        \"Machine learning models learn patterns from data.\",\n",
    "        \"Vector databases store embeddings for similarity search.\",\n",
    "    ]\n",
    "    print(reranking_rag(\"What is re-ranking in RAG?\", sample_corpus))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
