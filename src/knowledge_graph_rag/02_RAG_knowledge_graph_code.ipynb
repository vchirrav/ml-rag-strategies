{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rKDyFXP7yGVj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QgTPz2XyInB",
    "outputId": "2d2f2124-1946-44db-9aea-75da736abff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG uses retrieval through two methods: Vector Search and Keyword Search. Vector Search utilizes embeddings to find relevant information, while Keyword Search relies on specific keywords to retrieve data.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Knowledge Graph RAG: Structure documents as a graph and traverse for retrieval.\"\"\"\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def build_knowledge_graph() -> nx.DiGraph:\n",
    "    \"\"\"Build a simple knowledge graph from structured triples.\"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    triples = [\n",
    "        (\"RAG\", \"uses\", \"Retrieval\"),\n",
    "        (\"RAG\", \"uses\", \"Generation\"),\n",
    "        (\"Retrieval\", \"method\", \"Vector Search\"),\n",
    "        (\"Retrieval\", \"method\", \"Keyword Search\"),\n",
    "        (\"Generation\", \"powered_by\", \"LLM\"),\n",
    "        (\"LLM\", \"example\", \"GPT-4\"),\n",
    "        (\"Vector Search\", \"uses\", \"Embeddings\"),\n",
    "    ]\n",
    "    for subj, rel, obj in triples:\n",
    "        graph.add_edge(subj, obj, relation=rel)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def retrieve_subgraph(graph: nx.DiGraph, entity: str, depth: int = 2) -> str:\n",
    "    \"\"\"Retrieve facts by traversing neighbors up to a given depth.\"\"\"\n",
    "    if entity not in graph:\n",
    "        return f\"Entity '{entity}' not found in knowledge graph.\"\n",
    "\n",
    "    facts = []\n",
    "    visited = set()\n",
    "    queue = [(entity, 0)]\n",
    "    while queue:\n",
    "        node, d = queue.pop(0)\n",
    "        if node in visited or d > depth:\n",
    "            continue\n",
    "        visited.add(node)\n",
    "        for _, neighbor, data in graph.edges(node, data=True):\n",
    "            facts.append(f\"{node} --[{data['relation']}]--> {neighbor}\")\n",
    "            queue.append((neighbor, d + 1))\n",
    "    return \"\\n\".join(facts)\n",
    "\n",
    "\n",
    "def knowledge_graph_rag(query: str, entity: str) -> str:\n",
    "    graph = build_knowledge_graph()\n",
    "    context = retrieve_subgraph(graph, entity)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "    response = llm.invoke(\n",
    "        f\"Answer using the knowledge graph facts below.\\n\"\n",
    "        f\"Facts:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(knowledge_graph_rag(\"How does RAG use retrieval?\", \"RAG\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
